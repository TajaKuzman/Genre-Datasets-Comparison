wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.12.11
    framework: huggingface
    huggingface_version: 4.17.0
    is_jupyter_run: true
    is_kaggle_kernel: false
    python_version: 3.9.7
    start_time: 1659347684
    t:
      1:
      - 1
      - 5
      - 11
      - 31
      - 41
      - 49
      - 51
      3:
      - 1
      - 16
      4: 3.9.7
      5: 0.12.11
      6: 4.17.0
      8:
      - 1
      - 5
      9:
        2: simpletransformers
adafactor_beta1:
  desc: null
  value: null
adafactor_clip_threshold:
  desc: null
  value: 1.0
adafactor_decay_rate:
  desc: null
  value: -0.8
adafactor_eps:
  desc: null
  value:
  - 1.0e-30
  - 0.001
adafactor_relative_step:
  desc: null
  value: true
adafactor_scale_parameter:
  desc: null
  value: true
adafactor_warmup_init:
  desc: null
  value: true
adam_epsilon:
  desc: null
  value: 1.0e-08
best_model_dir:
  desc: null
  value: outputs/best_model
cache_dir:
  desc: null
  value: cache_dir/
config:
  desc: null
  value: {}
cosine_schedule_num_cycles:
  desc: null
  value: 0.5
custom_layer_parameters:
  desc: null
  value: []
custom_parameter_groups:
  desc: null
  value: []
dataloader_num_workers:
  desc: null
  value: 0
do_lower_case:
  desc: null
  value: false
dynamic_quantize:
  desc: null
  value: false
early_stopping_consider_epochs:
  desc: null
  value: false
early_stopping_delta:
  desc: null
  value: 0
early_stopping_metric:
  desc: null
  value: eval_loss
early_stopping_metric_minimize:
  desc: null
  value: true
early_stopping_patience:
  desc: null
  value: 3
encoding:
  desc: null
  value: null
eval_batch_size:
  desc: null
  value: 8
evaluate_during_training:
  desc: null
  value: true
evaluate_during_training_silent:
  desc: null
  value: true
evaluate_during_training_steps:
  desc: null
  value: 720
evaluate_during_training_verbose:
  desc: null
  value: true
evaluate_each_epoch:
  desc: null
  value: true
fp16:
  desc: null
  value: true
gradient_accumulation_steps:
  desc: null
  value: 1
labels_list:
  desc: null
  value:
  - Promotion of a Product
  - Forum
  - Instruction
  - News/Reporting
  - Opinionated News
  - Other
  - List of Summaries/Excerpts
  - Invitation
  - Opinion/Argumentation
  - Legal/Regulation
  - Information/Explanation
  - Review
  - Promotion of Services
  - Promotion
  - Announcement
  - Call
  - Correspondence
labels_map:
  desc: null
  value:
    Announcement: 14
    Call: 15
    Correspondence: 16
    Forum: 1
    Information/Explanation: 10
    Instruction: 2
    Invitation: 7
    Legal/Regulation: 9
    List of Summaries/Excerpts: 6
    News/Reporting: 3
    Opinion/Argumentation: 8
    Opinionated News: 4
    Other: 5
    Promotion: 13
    Promotion of Services: 12
    Promotion of a Product: 0
    Review: 11
lazy_delimiter:
  desc: null
  value: "\t"
lazy_labels_column:
  desc: null
  value: 1
lazy_loading:
  desc: null
  value: false
lazy_loading_start_line:
  desc: null
  value: 1
lazy_text_a_column:
  desc: null
  value: null
lazy_text_b_column:
  desc: null
  value: null
lazy_text_column:
  desc: null
  value: 0
learning_rate:
  desc: null
  value: 1.0e-05
local_rank:
  desc: null
  value: -1
logging_steps:
  desc: null
  value: 50
loss_args:
  desc: null
  value: {}
loss_type:
  desc: null
  value: null
manual_seed:
  desc: null
  value: null
max_grad_norm:
  desc: null
  value: 1.0
max_seq_length:
  desc: null
  value: 512
model_class:
  desc: null
  value: ClassificationModel
model_name:
  desc: null
  value: xlm-roberta-base
model_type:
  desc: null
  value: xlmroberta
multiprocessing_chunksize:
  desc: null
  value: -1
n_gpu:
  desc: null
  value: 1
no_cache:
  desc: null
  value: true
no_save:
  desc: null
  value: true
not_saved_args:
  desc: null
  value: []
num_train_epochs:
  desc: null
  value: 90
onnx:
  desc: null
  value: false
optimizer:
  desc: null
  value: AdamW
output_dir:
  desc: null
  value: outputs/
overwrite_output_dir:
  desc: null
  value: true
polynomial_decay_schedule_lr_end:
  desc: null
  value: 1.0e-07
polynomial_decay_schedule_power:
  desc: null
  value: 1.0
process_count:
  desc: null
  value: 6
quantized_model:
  desc: null
  value: false
regression:
  desc: null
  value: false
reprocess_input_data:
  desc: null
  value: true
save_best_model:
  desc: null
  value: true
save_eval_checkpoints:
  desc: null
  value: true
save_model_every_epoch:
  desc: null
  value: false
save_optimizer_and_scheduler:
  desc: null
  value: true
save_steps:
  desc: null
  value: -1
scheduler:
  desc: null
  value: linear_schedule_with_warmup
silent:
  desc: null
  value: true
skip_special_tokens:
  desc: null
  value: true
sliding_window:
  desc: null
  value: false
special_tokens_list:
  desc: null
  value: []
stride:
  desc: null
  value: 0.8
tensorboard_dir:
  desc: null
  value: null
thread_count:
  desc: null
  value: null
tie_value:
  desc: null
  value: 1
tokenizer_name:
  desc: null
  value: xlm-roberta-base
tokenizer_type:
  desc: null
  value: null
train_batch_size:
  desc: null
  value: 8
train_custom_parameters_only:
  desc: null
  value: false
use_cached_eval_features:
  desc: null
  value: true
use_early_stopping:
  desc: null
  value: false
use_hf_datasets:
  desc: null
  value: false
use_multiprocessing:
  desc: null
  value: false
use_multiprocessing_for_evaluation:
  desc: null
  value: true
wandb_kwargs:
  desc: null
  value: {}
wandb_project:
  desc: null
  value: GINCO-hyperparameter-search
warmup_ratio:
  desc: null
  value: 0.06
warmup_steps:
  desc: null
  value: 395
weight_decay:
  desc: null
  value: 0.0
