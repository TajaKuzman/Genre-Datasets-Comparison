{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Experiments with Wandb sweep\n","\n","I experimented with the Wandb sweep. However, at the end I was not satisfied with the combinations of hyperparameters that were found, so I chose epochs manually (by analying evaluation during training).\n","\n","Import all necessary libraries and install everything you need for training:"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:57:33.176902Z","iopub.status.busy":"2022-07-29T06:57:33.176491Z","iopub.status.idle":"2022-07-29T06:57:35.902248Z","shell.execute_reply":"2022-07-29T06:57:35.901146Z","shell.execute_reply.started":"2022-07-29T06:57:33.176817Z"},"trusted":true},"outputs":[],"source":["# install the libraries necessary for data wrangling, prediction and result analysis\n","import json\n","import numpy as np\n","import pandas as pd\n","import logging\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score,precision_score, recall_score\n","import torch\n","from numba import cuda\n","from sklearn.model_selection import train_test_split\n","from sklearn.dummy import DummyClassifier"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:57:35.908897Z","iopub.status.busy":"2022-07-29T06:57:35.907754Z","iopub.status.idle":"2022-07-29T06:57:47.363131Z","shell.execute_reply":"2022-07-29T06:57:47.361894Z","shell.execute_reply.started":"2022-07-29T06:57:35.908846Z"},"trusted":true},"outputs":[],"source":["# Install transformers\n","# (this needs to be done on Kaggle each time you start the session)\n","!pip install -q transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:57:47.366114Z","iopub.status.busy":"2022-07-29T06:57:47.365668Z","iopub.status.idle":"2022-07-29T06:58:15.436459Z","shell.execute_reply":"2022-07-29T06:58:15.435458Z","shell.execute_reply.started":"2022-07-29T06:57:47.366072Z"},"trusted":true},"outputs":[],"source":["# Install the simpletransformers\n","!pip install -q simpletransformers\n","from simpletransformers.classification import ClassificationModel"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:58:15.440070Z","iopub.status.busy":"2022-07-29T06:58:15.439205Z","iopub.status.idle":"2022-07-29T06:58:25.453542Z","shell.execute_reply":"2022-07-29T06:58:25.452416Z","shell.execute_reply.started":"2022-07-29T06:58:15.440031Z"},"trusted":true},"outputs":[],"source":["# Install wandb\n","!pip install -q wandb"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:58:25.456001Z","iopub.status.busy":"2022-07-29T06:58:25.455601Z","iopub.status.idle":"2022-07-29T06:58:25.462969Z","shell.execute_reply":"2022-07-29T06:58:25.462054Z","shell.execute_reply.started":"2022-07-29T06:58:25.455962Z"},"trusted":true},"outputs":[],"source":["import wandb"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:58:25.464749Z","iopub.status.busy":"2022-07-29T06:58:25.464432Z","iopub.status.idle":"2022-07-29T06:58:57.622701Z","shell.execute_reply":"2022-07-29T06:58:57.621772Z","shell.execute_reply.started":"2022-07-29T06:58:25.464717Z"},"trusted":true},"outputs":[],"source":["# Login to wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:58:57.624647Z","iopub.status.busy":"2022-07-29T06:58:57.624034Z","iopub.status.idle":"2022-07-29T06:58:57.929939Z","shell.execute_reply":"2022-07-29T06:58:57.928897Z","shell.execute_reply.started":"2022-07-29T06:58:57.624608Z"},"trusted":true},"outputs":[],"source":["# Clean the GPU cache\n","\n","cuda.select_device(0)\n","cuda.close()\n","cuda.select_device(0)\n","torch.cuda.empty_cache()\n"]},{"cell_type":"markdown","metadata":{},"source":["### Import the data"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:58:57.932449Z","iopub.status.busy":"2022-07-29T06:58:57.931401Z","iopub.status.idle":"2022-07-29T06:58:58.200601Z","shell.execute_reply":"2022-07-29T06:58:58.199538Z","shell.execute_reply.started":"2022-07-29T06:58:57.932412Z"},"trusted":true},"outputs":[],"source":["# FTD\n","train_df = pd.read_csv(\"/kaggle/input/genredatasetscomparison/FTD-train.txt\", sep=\"\\t\", index_col=0)\n","dev_df = pd.read_csv(\"/kaggle/input/genredatasetscomparison/FTD-dev.txt\", sep = \"\\t\", index_col = 0)\n","test_df = pd.read_csv(\"/kaggle/input/genredatasetscomparison/FTD-test.txt\", sep = \"\\t\", index_col = 0)\n","\n","print(\"FTD train shape: {}, Dev shape: {}, Test shape: {}.\".format(train_df.shape, dev_df.shape, test_df.shape))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:58:58.202595Z","iopub.status.busy":"2022-07-29T06:58:58.202243Z","iopub.status.idle":"2022-07-29T06:58:58.216854Z","shell.execute_reply":"2022-07-29T06:58:58.216026Z","shell.execute_reply.started":"2022-07-29T06:58:58.202559Z"},"trusted":true},"outputs":[],"source":["train_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Training and testing"]},{"cell_type":"markdown","metadata":{},"source":["We will use the multilingual XLM-RoBERTa model\n","https://huggingface.co/xlm-roberta-base"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:58:58.220470Z","iopub.status.busy":"2022-07-29T06:58:58.220213Z","iopub.status.idle":"2022-07-29T06:58:58.225378Z","shell.execute_reply":"2022-07-29T06:58:58.224358Z","shell.execute_reply.started":"2022-07-29T06:58:58.220447Z"},"trusted":true},"outputs":[],"source":["# Create a file to save results into (you can find it under Data: Output). Be careful, run this step only once to not overwrite the results file.\n","results = []\n","\n","with open(\"FTD-Experiments-Results.json\", \"w\") as results_file:\n","    json.dump(results,results_file, indent= \"\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:58:58.227244Z","iopub.status.busy":"2022-07-29T06:58:58.226897Z","iopub.status.idle":"2022-07-29T06:58:58.239187Z","shell.execute_reply":"2022-07-29T06:58:58.237958Z","shell.execute_reply.started":"2022-07-29T06:58:58.227211Z"},"trusted":true},"outputs":[],"source":["# Open the main results file:\n","\n","previous_results_file = open(\"./FTD-Experiments-Results.json\")\n","previous_results = json.load(previous_results_file)\n","len(previous_results)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:58:58.241405Z","iopub.status.busy":"2022-07-29T06:58:58.240899Z","iopub.status.idle":"2022-07-29T06:58:58.247785Z","shell.execute_reply":"2022-07-29T06:58:58.246867Z","shell.execute_reply.started":"2022-07-29T06:58:58.241369Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:58:58.249620Z","iopub.status.busy":"2022-07-29T06:58:58.249143Z","iopub.status.idle":"2022-07-29T06:58:58.262838Z","shell.execute_reply":"2022-07-29T06:58:58.261407Z","shell.execute_reply.started":"2022-07-29T06:58:58.249586Z"},"trusted":true},"outputs":[],"source":["# Create a list of labels\n","LABELS = train_df.labels.unique().tolist()\n","LABELS"]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparameter sweeps"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Configure the WandB sweep for hyperparameter search\n","sweep_config = {\n","    \"method\": \"grid\",  # random, grid, bayes\n","    \"metric\": {\"name\": \"train_loss\", \"goal\": \"minimize\"},\n","    \"parameters\": {\n","        \"num_train_epochs\": {\"values\": [10, 20, 30, 50, 70, 90]},\n","    },\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Initialize the sweep\n","sweep_id = wandb.sweep(sweep_config, project=\"FTD-learning-hyperparameter-sweep\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Add logging\n","logging.basicConfig(level=logging.INFO)\n","transformers_logger = logging.getLogger(\"transformers\")\n","transformers_logger.setLevel(logging.WARNING)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create a function that will be ran inside the sweep\n","def train():\n","    # Initialize a new wandb run\n","    wandb.init()\n","\n","    # Create a TransformerModel\n","    roberta_base_model = ClassificationModel(\n","        \"xlmroberta\", \"xlm-roberta-base\",\n","        num_labels=len(LABELS),\n","        use_cuda=True,\n","        args= {\n","            \"overwrite_output_dir\": True,\n","            \"labels_list\": LABELS,\n","            \"no_cache\": True,\n","            \"no_save\": True,\n","            \"max_seq_length\": 512,\n","            \"save_steps\": -1,\n","            \"evaluate_during_training\":True,\n","            'logging_steps': 10,\n","            'evaluate_during_training_steps': 10,\n","            \"use_cached_eval_features\": True,\n","            \"reprocess_input_data\": True,\n","            \"silent\": True,\n","            \"wandb_project\": 'FTD-learning-hyperparameter-sweep',\n","            \"sweep_config\":wandb.config\n","            }\n","        )\n","\n","    # Train the model\n","    roberta_base_model.train_model(train_df, eval_df=dev_df)\n","\n","    # Evaluate the model\n","    roberta_base_model.eval_model(dev_df)\n","\n","    # Sync wandb\n","    wandb.join()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Run the sweeps\n","wandb.agent(sweep_id, train, count= 10)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.6.9 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":4}
